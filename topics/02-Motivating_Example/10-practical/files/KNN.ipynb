{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0abbe964",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours\n",
    "\n",
    " * Animation of KNN\n",
    " * Used to generate images for slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d52960",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd893c9",
   "metadata": {
    "tags": [
     "load"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f3c35",
   "metadata": {},
   "source": [
    "Load in a dataset\n",
    " * Should have numerical features\n",
    " * Labeled (supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9840792c",
   "metadata": {
    "tags": [
     "dataset"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "dataset_name = \"IRIS\"\n",
    "X, y, target_names = iris.data, iris.target, iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0309654e",
   "metadata": {},
   "source": [
    "KNN works in arbitrary dimensions, but to visualise it we need to drop down to two. Using Linear Discrimant Analysis (LDA) we can fid the best two dimensions to separate the classes, i.e., the best direction to view the data so that the classes are separated as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee213c",
   "metadata": {
    "tags": [
     "lda"
    ]
   },
   "outputs": [],
   "source": [
    "# drop down to 2D so we can visualise KNN\n",
    "if False:\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "    X = lda.fit_transform(X, y)\n",
    "    axis_labels = None\n",
    "else:\n",
    "    X = X[:,:2]\n",
    "    axis_labels = [\"Sepal length (cm)\", \"Sepal width (cm)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d4be5",
   "metadata": {},
   "source": [
    "FOR YOU: Lookup up discriminant analysis online? How is it similiar to and how is it different to classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295759d5",
   "metadata": {},
   "source": [
    "Scaling features is necessary before KNN to avoid undue influence by the dominant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a7dce",
   "metadata": {
    "tags": [
     "scale"
    ]
   },
   "outputs": [],
   "source": [
    "# scale features (to mean=0, std=1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c49c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the order observation order - for later visualisation\n",
    "np.random.seed(42)\n",
    "idx = np.random.permutation(range(len(y)))\n",
    "X, y = X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad218f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import Counter\n",
    "\n",
    "n = X.shape[0]\n",
    "n_classes = len(target_names)\n",
    "\n",
    "markers = ['^', 's', '*']\n",
    "colors =   ['#377eb8', '#4daf4a', '#a65628', '#984ea3','#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "m = widgets.IntSlider(value=10, min=1, max=n-1, step=1)\n",
    "k = widgets.IntSlider(value=1, min=1, max=20, step=1)\n",
    "summary = widgets.Textarea(value='', layout={'height':'150px', 'width': 'auto'}, disabled=False)\n",
    "ui = widgets.VBox([\n",
    "    widgets.HBox([\n",
    "        widgets.VBox([widgets.Label('Number of observations in train set: $m$'), m]),\n",
    "        widgets.VBox([widgets.Label('Number of neighbours: $k$'), k])\n",
    "    ]),\n",
    "    summary])\n",
    "\n",
    "def f(m,k, show_fig=True, save_fig=False, show_region=True, size=100):\n",
    "    \n",
    "    global summary\n",
    "    \n",
    "    \n",
    "    message = \"\"\n",
    "    if k>m:\n",
    "        message += f\"Reducing k to {m}, since number of neighbours cannot be bigger than number of observation in train set.\\n\"\n",
    "        k = m\n",
    "    \n",
    "    # train set consists of first m observations\n",
    "    X_train, y_train = X[:m], y[:m]\n",
    "\n",
    "    # new observation is (m+1)(th) observation\n",
    "    x_new =  X[m]\n",
    "\n",
    "    # compute distances from new point to all others in train\n",
    "    distances = np.linalg.norm(X_train - x_new,axis=1)\n",
    "    neighbours = sorted(zip(distances,y_train), key=lambda x: x[0])\n",
    "\n",
    "    # get min radius to reach k nearest neighbours \n",
    "    radius = neighbours[k-1][0]\n",
    "\n",
    "    message +=  f\"Location of new observation is ({x_new[0]:.2f}, {x_new[1]:.2f})\\n\" \\\n",
    "        f\"Radius needed to reach {k} nearest neighbours = {radius:.2f}\"\n",
    "    message += \"\\nCounting neighbours ...\"\n",
    "    counts = Counter([a[1] for a in neighbours[:k]])\n",
    "    max_count = max([v for _,v in counts.items()])\n",
    "    max_class = [c for c,v in counts.items() if v==max_count]\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "         message += f\"\\n\\t{target_names[i]:20s} {counts[i]:3d} {'MAX' if i in max_class else ''}\"\n",
    "    if len(max_class)==1:\n",
    "        message += f\"\\n{k} nearest neighours suggests that new observation should be in class '{target_names[max_class[0]]}'.\"\n",
    "    else:\n",
    "        message += f\"\\nHave tie in {k} nearest neighours, reduce k by one and rerun.\"\n",
    "    # comment on unsafe k\n",
    "    if k % n_classes==0:\n",
    "        message += f\"\\nNote: Number of neighbours k={k} should not be a multiple of number of classes = {n_classes}.\"\n",
    "    \n",
    "    if show_fig or save_fig:\n",
    "        fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "    \n",
    "        # add a circle\n",
    "        if show_region:\n",
    "            circle = plt.Circle(x_new, radius, color='r', alpha=0.2)\n",
    "            ax.add_patch(circle)\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            plt.scatter(X_train[y_train==i, 0], X_train[y_train==i, 1], s=size, marker=markers[i], alpha=.8, color=colors[i],  label=target_names[i])\n",
    "        plt.scatter(x_new[0], x_new[1], marker='$?$', s=size, alpha=.8, color='red')\n",
    "\n",
    "        plt.legend(loc='lower left', shadow=False, scatterpoints=1, frameon=True)\n",
    "        #plt.axis('equal')\n",
    "        plt.ylim(-2.6,2.6)\n",
    "        plt.xlim(-2.6,2.6)\n",
    "        if axis_labels is not None:\n",
    "            plt.xlabel(axis_labels[0])\n",
    "            plt.ylabel(axis_labels[1])\n",
    "        plt.title(f'{dataset_name} dataset (m={m}, k={k})');\n",
    "\n",
    "    summary.value = message\n",
    "        \n",
    "    if save_fig:\n",
    "        filename = f\"output/knn_{dataset_name}_{m}_{k}_{int(show_region)}.pdf\"\n",
    "        plt.savefig(filename, bbox_inches=\"tight\")\n",
    "    if not show_fig: plt.close()\n",
    "\n",
    "    return {\"X_train\":X_train, \"y_train\":y_train, \"x_new\":x_new, \"distances\": distances, \"counts\": counts}\n",
    "\n",
    "out = widgets.interactive_output(f, {'m': m, 'k': k})\n",
    "\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d25f9",
   "metadata": {},
   "source": [
    "## Visualising KNN in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e381814",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(26,1, show_fig=1, save_fig=1, show_region=0, size=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(26,1, show_fig=0, save_fig=1, show_region=0, size=200);\n",
    "f(26,1, show_fig=0, save_fig=1, show_region=1, size=200);\n",
    "f(26,3, show_fig=0, save_fig=1, show_region=1, size=200);\n",
    "f(26,5, show_fig=0, save_fig=1, show_region=1, size=200);\n",
    "f(26,7, show_fig=0, save_fig=1, show_region=1, size=200);\n",
    "f(26,9, show_fig=0, save_fig=1, show_region=1, size=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d2d5e",
   "metadata": {},
   "source": [
    "## Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fadd63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "dataset_name = \"IRIS\"\n",
    "X, y, target_names = iris.data[:, :2], iris.target, iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4785c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4aa378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desision_boundaries(k, show_fig=True):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light, shading='auto')\n",
    "\n",
    "    # Plot also the training points\n",
    "    for i in range(3):\n",
    "        plt.scatter(X[y==i,0], X[y==i, 1], c=['#FF0000', '#00FF00', '#0000FF'][i], marker=markers[i])\n",
    "    plt.xlabel('sepal length (cm)')\n",
    "    plt.ylabel('sepal width (cm)')\n",
    "    plt.title(f\"{dataset_name} k-NN decision boundaries ($k={k}$)\")\n",
    "    plt.axis('tight')\n",
    "    plt.savefig(f\"output/knn_{dataset_name}_decision_boundary_{k}.pdf\")\n",
    "    if show_fig:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [1,3,5,7,17]:\n",
    "    desision_boundaries(k,show_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c120c83",
   "metadata": {},
   "source": [
    "FOR YOU: What happens to the decision boundaries as k increases? How might you find an optimal value of k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41f690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
